<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.15.1 by Michael Rose
  Copyright 2013-2019 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE
-->
<html lang="en" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>Automatic scientific abstract text generation | Aditya Jaishankar</title>
<meta name="description" content="Basic Imports">



<meta property="og:type" content="article">
<meta property="og:locale" content="en_US">
<meta property="og:site_name" content="Aditya Jaishankar">
<meta property="og:title" content="Automatic scientific abstract text generation">
<meta property="og:url" content="http://localhost:4000/projects/rnn-arxiv/">


  <meta property="og:description" content="Basic Imports">







  <meta property="article:published_time" content="2019-12-20T21:51:21-05:00">





  

  


<link rel="canonical" href="http://localhost:4000/projects/rnn-arxiv/">







  <script type="application/ld+json">
    {
      "@context": "https://schema.org",
      "@type": "Person",
      "name": "Aditya Jaishankar",
      "url": "http://localhost:4000",
      "sameAs": null
    }
  </script>







<!-- end _includes/seo.html -->


<link href="/feed.xml" type="application/atom+xml" rel="alternate" title="Aditya Jaishankar Feed">

<!-- https://t.co/dKP3o1e -->
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/main.css">

<!--[if IE ]>
  <style>
    /* old IE unsupported flexbox fixes */
    .greedy-nav .site-title {
      padding-right: 3em;
    }
    .greedy-nav button {
      position: absolute;
      top: 0;
      right: 0;
      height: 100%;
    }
  </style>
<![endif]-->



    <!-- start custom head snippets -->

<!-- insert favicons. use https://realfavicongenerator.net/ -->







<link href="https://fonts.googleapis.com/css?family=Crimson+Text" rel="stylesheet">





<!-- end custom head snippets -->

  </head>

  <body class="layout--single">

    <!--[if lt IE 9]>
<div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience.</div>
<![endif]-->

    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        
        <a class="site-title" href="/"> </a>
        <ul class="visible-links"><li class="masthead__menu-item">
              <a href="/" >Home</a>
            </li><li class="masthead__menu-item">
              <a href="/coursework/" >ML/AI Coursework</a>
            </li><li class="masthead__menu-item">
              <a href="/projects/" >Projects</a>
            </li><li class="masthead__menu-item">
              <a href="/research/" >Ph.D. Research</a>
            </li><li class="masthead__menu-item">
              <a href="/publications/" >Publications</a>
            </li></ul>
        
        <button class="search__toggle" type="button">
          <span class="visually-hidden">Toggle search</span>
          <svg class="icon" width="16" height="16" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 15.99 16">
            <path d="M15.5,13.12L13.19,10.8a1.69,1.69,0,0,0-1.28-.55l-0.06-.06A6.5,6.5,0,0,0,5.77,0,6.5,6.5,0,0,0,2.46,11.59a6.47,6.47,0,0,0,7.74.26l0.05,0.05a1.65,1.65,0,0,0,.5,1.24l2.38,2.38A1.68,1.68,0,0,0,15.5,13.12ZM6.4,2A4.41,4.41,0,1,1,2,6.4,4.43,4.43,0,0,1,6.4,2Z" transform="translate(-.01)"></path>
          </svg>
        </button>
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">Toggle menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <div class="initial-content">
      


  
    



<nav class="breadcrumbs">
  <ol itemscope itemtype="https://schema.org/BreadcrumbList">
    
    
    
      
        <li itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
          <a href="http://localhost:4000/" itemprop="item"><span itemprop="name">Home</span></a>
          <meta itemprop="position" content="1" />
        </li>
        <span class="sep">/</span>
      
      
        
        <li itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
          <a href="/projects" itemprop="item"><span itemprop="name">Projects</span></a>
          <meta itemprop="position" content="2" />
        </li>
        <span class="sep">/</span>
      
    
      
      
        <li class="current">Automatic scientific abstract text generation</li>
      
    
  </ol>
</nav>

  


<div id="main" role="main">
  
  <div class="sidebar sticky">
  


<div itemscope itemtype="https://schema.org/Person">

  
    <div class="author__avatar">
      

      
        <img src="/assets/images/profile.jpg" alt="Aditya Jaishankar" itemprop="image">
      
    </div>
  

  <div class="author__content">
    
      <h3 class="author__name" itemprop="name">Aditya Jaishankar</h3>
    
    
      <p class="author__bio" itemprop="description">
        <b>Ph.D., Massachusetts Institute of Technology.</b><br>Soft Condensed Matter Physicist and Surface Scientist.
      </p>
    
  </div>

  <div class="author__urls-wrapper">
    <button class="btn btn--inverse">Follow</button>
    <ul class="author__urls social-icons">
      
        <li itemprop="homeLocation" itemscope itemtype="https://schema.org/Place">
          <i class="fas fa-fw fa-map-marker-alt" aria-hidden="true"></i> <span itemprop="name">New Jersey, USA</span>
        </li>
      

      
        
          
        
          
            <li><a href="https://www.github.com/aditya-jaishankar/" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-github" aria-hidden="true"></i> GitHub</a></li>
          
        
          
            <li><a href="https://www.linkedin.com/in/adityajaishankar" rel="nofollow noopener noreferrer"><i class="fab fa-linkedin" aria-hidden="true"></i> LinkedIn</a></li>
          
        
          
            <li><a href="/assets/misc/Resume_Jaishankar_191020.pdf" rel="nofollow noopener noreferrer"><i class="fas fa-file-alt" aria-hidden="true"></i> Resume</a></li>
          
        
      

      

      
        <li>
          <a href="mailto:aditya1642@gmail.com">
            <meta itemprop="email" content="aditya1642@gmail.com" />
            <i class="fas fa-fw fa-envelope-square" aria-hidden="true"></i> Email
          </a>
        </li>
      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      <!--
  <li>
    <a href="http://link-to-whatever-social-network.com/user/" itemprop="sameAs" rel="nofollow noopener noreferrer">
      <i class="fas fa-fw" aria-hidden="true"></i> Custom Social Profile Link
    </a>
  </li>
-->
    </ul>
  </div>
</div>

  
  </div>


  <article class="page" itemscope itemtype="https://schema.org/CreativeWork">
    <meta itemprop="headline" content="Automatic scientific abstract text generation">
    <meta itemprop="description" content="Basic Imports">
    
    

    <div class="page__inner-wrap">
      
        <header>
          <h1 id="page-title" class="page__title" itemprop="headline">Automatic scientific abstract text generation
</h1>
          
        </header>
      

      <section class="page__content" itemprop="text">
        
        <h2 id="basic-imports">Basic Imports</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">urllib</span>
<span class="kn">import</span> <span class="nn">re</span>
<span class="kn">from</span> <span class="nn">bs4</span> <span class="kn">import</span> <span class="n">BeautifulSoup</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="kn">from</span> <span class="nn">tqdm</span> <span class="kn">import</span> <span class="n">tqdm</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="c"># import itertools</span>

<span class="kn">import</span> <span class="nn">string</span>
<span class="kn">import</span> <span class="nn">random</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="n">nn</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">Dataset</span><span class="p">,</span> <span class="n">DataLoader</span>
<span class="kn">import</span> <span class="nn">torch.optim</span> <span class="k">as</span> <span class="n">optim</span>
<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s">'cuda:0'</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s">'cpu'</span><span class="p">)</span>

<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">OneHotEncoder</span>
</code></pre></div></div>

<p>The first step is to be able to extract all the data. For this we use <code class="highlighter-rouge">BeautifulSoup</code> to extract all the text between the <code class="highlighter-rouge">&lt;summary&gt;</code> and <code class="highlighter-rouge">&lt;/summary&gt;</code> tags. We then have a list of all abstracts. We can then look at it from a character level perspective, train an LSTM (say we use Karpathy’s architecture instead of fooling around with different architectures) and then have it output an abstract of say 500 words. This should be an interesting exercise!</p>

<h2 id="downloading-the-corpus-and-extracting-the-abstracts">Downloading the corpus and extracting the abstracts</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">downloadDataCorpus</span><span class="p">(</span><span class="n">parsehtml</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">downloadfile</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>
    <span class="s">"""
    Creates the corpus.
    Inputs:
        parsehtml: whether to run this function at all. I should normally have this
        corpus presaved as a text file
        downloadfile: whether to download the data or not. This seems to be the speed
        bottleneck. 
    """</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">parsehtml</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">None</span>
    
    <span class="k">if</span> <span class="n">downloadfile</span><span class="p">:</span>
        <span class="n">url</span> <span class="o">=</span> <span class="s">'http://export.arxiv.org/api/query?search_query=all:polymer&amp;start=0&amp;max_results=10000'</span>
        <span class="n">f</span> <span class="o">=</span> <span class="n">urllib</span><span class="o">.</span><span class="n">request</span><span class="o">.</span><span class="n">urlopen</span><span class="p">(</span><span class="n">url</span><span class="p">)</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
        <span class="n">soup</span> <span class="o">=</span> <span class="n">BeautifulSoup</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="s">'html.parser'</span><span class="p">)</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s">r'./rawData.txt'</span><span class="p">,</span> <span class="s">'w+'</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s">'utf-8'</span><span class="p">)</span> <span class="k">as</span> <span class="n">out</span><span class="p">:</span>
            <span class="n">out</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">soup</span><span class="p">))</span>
    <span class="n">soup</span> <span class="o">=</span> <span class="n">BeautifulSoup</span><span class="p">(</span><span class="nb">open</span><span class="p">(</span><span class="s">'./rawData.txt'</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s">'utf-8'</span><span class="p">),</span> <span class="s">'html.parser'</span><span class="p">)</span>
    <span class="n">abstracts</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">summary</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">soup</span><span class="o">.</span><span class="n">find_all</span><span class="p">(</span><span class="s">'summary'</span><span class="p">)):</span>
        <span class="n">abstracts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">summary</span><span class="o">.</span><span class="n">text</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s">'</span><span class="se">\n</span><span class="s">'</span><span class="p">,</span> <span class="s">' '</span><span class="p">)</span><span class="o">.</span><span class="n">strip</span><span class="p">())</span>
    <span class="n">abstracts</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">abstracts</span><span class="p">)</span>
    <span class="n">np</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s">'./abstracts.npy'</span><span class="p">,</span> <span class="n">abstracts</span><span class="p">)</span>

<span class="n">downloadDataCorpus</span><span class="p">(</span><span class="n">parsehtml</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">downloadfile</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

<span class="n">corpus</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s">'./abstracts.npy'</span><span class="p">)</span>
<span class="n">all_text</span> <span class="o">=</span> <span class="s">''</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">corpus</span><span class="p">)</span>  <span class="c"># combine all abstracts into a single string</span>
</code></pre></div></div>

<h2 id="defining-some-utility-functions">Defining some utility functions</h2>

<h3 id="encoding-the-characters-into-numbers">Encoding the characters into numbers</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">all_characters</span> <span class="o">=</span> <span class="n">string</span><span class="o">.</span><span class="n">printable</span>
<span class="n">n_characters</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">all_characters</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">encoder</span><span class="p">(</span><span class="n">string</span><span class="p">):</span>
    <span class="s">"""
    This function takes a string and tokenizes it by assigning it a unique index
    """</span>
    <span class="n">encoded</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">string</span><span class="p">))</span><span class="o">.</span><span class="nb">long</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">char</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">string</span><span class="p">):</span>
        <span class="n">encoded</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">all_characters</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">char</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">encoded</span>

<span class="k">def</span> <span class="nf">save</span><span class="p">():</span>
    <span class="s">"""
    To save any intermediate models while training in case I give a
    KeyboardInterrupt.
    """</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">lstm_model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="s">'./arxiv-generator2.pt'</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">None</span>
</code></pre></div></div>

<h3 id="defining-a-dataset-object-to-generate-the-data">Defining a <code class="highlighter-rouge">Dataset</code> object to generate the data</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">trainingSet</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">all_text</span><span class="p">,</span> <span class="n">str_length</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">trainingSet</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">all_text</span> <span class="o">=</span> <span class="n">all_text</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">str_length</span> <span class="o">=</span> <span class="n">str_length</span>

    <span class="k">def</span> <span class="nf">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">all_text</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>
        <span class="n">seed</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">all_text</span><span class="p">)</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">str_length</span><span class="p">)</span>
        <span class="n">sequence</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">all_text</span><span class="p">[</span><span class="n">seed</span><span class="p">:</span><span class="n">seed</span><span class="o">+</span><span class="n">str_length</span><span class="p">]</span>
        <span class="n">inp</span> <span class="o">=</span> <span class="n">encoder</span><span class="p">(</span><span class="n">sequence</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
        <span class="n">target</span> <span class="o">=</span> <span class="n">encoder</span><span class="p">(</span><span class="n">sequence</span><span class="p">[</span><span class="mi">1</span><span class="p">:])</span>
        <span class="k">return</span> <span class="n">inp</span><span class="p">,</span> <span class="n">target</span>

<span class="n">str_length</span> <span class="o">=</span> <span class="mi">25</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">trainingSet</span><span class="p">(</span><span class="n">all_text</span><span class="p">,</span> <span class="n">str_length</span><span class="p">)</span>
<span class="n">dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
</code></pre></div></div>

<h2 id="defining-the-structure-of-the-lstm">Defining the structure of the LSTM</h2>

<p>Next need to define my lstm class. The need to define the training loop. Then need to define an abstract generator loop. if count(‘.’) &gt; 10, then break (this would keep the abstract a reasonable length).</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">LSTM</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>


    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">INPUT_SIZE</span><span class="p">,</span> <span class="n">HIDDEN_SIZE</span><span class="p">,</span> <span class="n">OUTPUT_SIZE</span><span class="p">,</span> <span class="n">num_layers</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">LSTM</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">input_size</span> <span class="o">=</span> <span class="n">INPUT_SIZE</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span> <span class="o">=</span> <span class="n">HIDDEN_SIZE</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output_size</span> <span class="o">=</span> <span class="n">OUTPUT_SIZE</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_layers</span> <span class="o">=</span> <span class="n">num_layers</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">INPUT_SIZE</span><span class="p">,</span> <span class="n">HIDDEN_SIZE</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lstm</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LSTM</span><span class="p">(</span><span class="n">HIDDEN_SIZE</span><span class="p">,</span> <span class="n">HIDDEN_SIZE</span><span class="p">,</span> <span class="n">num_layers</span><span class="o">=</span><span class="n">num_layers</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">HIDDEN_SIZE</span><span class="p">,</span> <span class="n">OUTPUT_SIZE</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inp</span><span class="p">,</span> <span class="n">hidden</span><span class="p">):</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">inp</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="c"># Think about what exactly is meant by batch_size here</span>
        <span class="n">encoded</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">inp</span><span class="p">)</span>
        <span class="n">output</span><span class="p">,</span> <span class="n">hidden</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lstm</span><span class="p">(</span><span class="n">encoded</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">hidden</span><span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">output</span><span class="p">,</span> <span class="n">hidden</span>
    
    <span class="c"># Probably lets me handle predictions very nicely</span>
    <span class="k">def</span> <span class="nf">forward2</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inp</span><span class="p">,</span> <span class="n">hidden</span><span class="p">):</span>
        <span class="n">encoded</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">inp</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>
        <span class="n">output</span><span class="p">,</span> <span class="n">hidden</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lstm</span><span class="p">(</span><span class="n">encoded</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">hidden</span><span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">output</span><span class="p">,</span> <span class="n">hidden</span>

    <span class="k">def</span> <span class="nf">initHidden</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_layers</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_layers</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">))</span>
</code></pre></div></div>

<h2 id="defining-the-training-loop">Defining the training loop</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="n">target</span><span class="p">):</span>
    <span class="n">hidden</span> <span class="o">=</span> <span class="n">lstm_model</span><span class="o">.</span><span class="n">initHidden</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>

    <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">str_length</span><span class="o">-</span><span class="mi">1</span><span class="p">):</span>
        <span class="n">output</span><span class="p">,</span> <span class="n">hidden</span> <span class="o">=</span> <span class="n">lstm_model</span><span class="p">(</span><span class="n">inp</span><span class="p">[:,</span> <span class="n">i</span><span class="p">],</span> <span class="n">hidden</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">+=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">target</span><span class="p">[:,</span> <span class="n">i</span><span class="p">])</span>

    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

    <span class="k">return</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="o">/</span><span class="n">str_length</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">NUM_EPOCHS</span> <span class="o">=</span> <span class="mi">1000000</span>
<span class="n">INPUT_SIZE</span> <span class="o">=</span> <span class="n">n_characters</span>
<span class="n">HIDDEN_SIZE</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">OUTPUT_SIZE</span> <span class="o">=</span> <span class="n">n_characters</span>
<span class="n">num_layers</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">lstm_model</span> <span class="o">=</span> <span class="n">LSTM</span><span class="p">(</span><span class="n">INPUT_SIZE</span><span class="p">,</span> <span class="n">HIDDEN_SIZE</span><span class="p">,</span> <span class="n">OUTPUT_SIZE</span><span class="p">,</span> <span class="n">num_layers</span><span class="o">=</span><span class="n">num_layers</span><span class="p">)</span>

<span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">lstm_model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=.</span><span class="mo">001</span><span class="p">)</span>
<span class="n">loss_fn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
<span class="n">lstm_model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>LSTM(
  (encoder): Embedding(100, 128)
  (lstm): LSTM(128, 128, num_layers=2)
  (decoder): Linear(in_features=128, out_features=100, bias=True)
)
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">all_losses</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">loss_avg</span> <span class="o">=</span> <span class="mi">0</span>

<span class="k">try</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">NUM_EPOCHS</span><span class="p">)):</span>
        <span class="n">inp</span><span class="p">,</span> <span class="n">target</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">dataloader</span><span class="p">))</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">train</span><span class="p">(</span><span class="n">inp</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">target</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">))</span>
        <span class="n">loss_avg</span> <span class="o">+=</span> <span class="n">loss</span>

        <span class="k">if</span> <span class="p">(</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="mi">10000</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">print</span><span class="p">(</span><span class="s">'loss so far: '</span><span class="p">,</span> <span class="n">loss</span><span class="p">)</span>
            <span class="n">all_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss_avg</span><span class="p">)</span>
            <span class="n">loss_avg</span> <span class="o">=</span> <span class="mi">0</span>

<span class="k">except</span> <span class="nb">KeyboardInterrupt</span><span class="p">:</span>
        <span class="k">print</span><span class="p">(</span><span class="s">'Saving model...'</span><span class="p">)</span>
        <span class="n">save</span><span class="p">()</span>

<span class="n">save</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">all_losses</span><span class="p">)),</span> <span class="n">all_losses</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<h3 id="code-to-generate-the-text">Code to generate the text</h3>

<p>Once the model has been trained, we can use it to generate text. Note that instead of using the character expected from the argmax of the highest probability, we actually sample from a multinomial distribution based on an ‘activation’ temperature. Higher the value of temperature, more noise we would expect to see, and a larger number os spelling and other errors. However, very low temperatures would give very little diversity and we end up generating text in a deterministic manner given the priming string.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">generate</span><span class="p">(</span><span class="n">decoder</span><span class="p">,</span> <span class="n">prime_str</span><span class="o">=</span><span class="s">'Here'</span><span class="p">,</span> <span class="n">predict_len</span><span class="o">=</span><span class="mi">600</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">cuda</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>
    <span class="n">hidden_state</span><span class="p">,</span> <span class="n">cell_state</span> <span class="o">=</span> <span class="n">decoder</span><span class="o">.</span><span class="n">initHidden</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">hidden</span> <span class="o">=</span> <span class="n">hidden_state</span><span class="o">.</span><span class="n">cpu</span><span class="p">(),</span> <span class="n">cell_state</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span>
    <span class="n">prime_input</span> <span class="o">=</span> <span class="n">encoder</span><span class="p">(</span><span class="n">prime_str</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">predicted</span> <span class="o">=</span> <span class="n">prime_str</span>

    <span class="c"># Use priming string to "build up" hidden state</span>
    <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">prime_str</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">_</span><span class="p">,</span> <span class="n">hidden</span> <span class="o">=</span> <span class="n">decoder</span><span class="p">(</span><span class="n">prime_input</span><span class="p">[:,</span><span class="n">p</span><span class="p">],</span> <span class="n">hidden</span><span class="p">)</span>
        
    <span class="n">inp</span> <span class="o">=</span> <span class="n">prime_input</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    
    <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">predict_len</span><span class="p">):</span>
        <span class="n">output</span><span class="p">,</span> <span class="n">hidden</span> <span class="o">=</span> <span class="n">decoder</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="n">hidden</span><span class="p">)</span>
        
        <span class="c"># Sample from the network as a multinomial distribution</span>
        <span class="n">output_dist</span> <span class="o">=</span> <span class="n">output</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">div</span><span class="p">(</span><span class="n">temperature</span><span class="p">)</span><span class="o">.</span><span class="n">exp</span><span class="p">()</span>
        <span class="n">top_i</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">multinomial</span><span class="p">(</span><span class="n">output_dist</span><span class="p">,</span> <span class="mi">1</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

        <span class="c"># Add predicted character to string and use as next input</span>
        <span class="n">predicted_char</span> <span class="o">=</span> <span class="n">all_characters</span><span class="p">[</span><span class="n">top_i</span><span class="p">]</span>
        <span class="n">predicted</span> <span class="o">+=</span> <span class="n">predicted_char</span>
        <span class="n">inp</span> <span class="o">=</span> <span class="n">encoder</span><span class="p">(</span><span class="n">predicted_char</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">predicted</span>

<span class="n">lstm_model_pred</span> <span class="o">=</span> <span class="n">LSTM</span><span class="p">(</span><span class="n">INPUT_SIZE</span><span class="p">,</span> <span class="n">HIDDEN_SIZE</span><span class="p">,</span> <span class="n">OUTPUT_SIZE</span><span class="p">,</span> <span class="n">num_layers</span><span class="o">=</span><span class="n">num_layers</span><span class="p">)</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span>

<span class="n">lstm_model_pred</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s">'./arxiv-generator2.pt'</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s">'cpu'</span><span class="p">)))</span>
<span class="n">lstm_model_pred</span><span class="o">.</span><span class="nb">eval</span><span class="p">()</span>
<span class="n">generate</span><span class="p">(</span><span class="n">lstm_model_pred</span><span class="p">)</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>'Here we study the self-avoiding walks leads to the semi-flexibon. This behavior with enhanced as displacement is influenced by the microstrating Fermi statistical models as the large size in large attractive model based on a potential formalism. The model is explored theory is defined as the T$_{0}$ concentrational statistics to show that the polymers in DNA structure can be extended to the mechanical jump above the constraint in turn on a polymer network and simulations where our approach to the beam constant exists a consecutive circuits of the electrically to unfold in polymer chains and electr'
</code></pre></div></div>

<p>We see that the abstract makes very good grammatical and lexical sense, and nearly reads like an accepted abstract!</p>

        
      </section>

      <footer class="page__meta">
        
        


        
      </footer>

      

      
  <nav class="pagination">
    
      <a href="/projects/neuralpde/" class="pagination--pager" title="Solution of partial differential equations using neural networks
">Previous</a>
    
    
      <a href="/projects/utils/" class="pagination--pager" title="Molecular solubility from polar charge density images: utils file
">Next</a>
    
  </nav>

    </div>

    
  </article>

  
  
</div>

    </div>

    
      <div class="search-content">
        <div class="search-content__inner-wrap"><input type="text" id="search" class="search-input" tabindex="-1" placeholder="Enter your search term..." />
    <div id="results" class="results"></div></div>

      </div>
    

    <div class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        <div class="page__footer-follow">
  <ul class="social-icons">
    
      <li><strong>Follow:</strong></li>
    

    
      
        
      
    

    <li><a href="/feed.xml"><i class="fas fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
  </ul>
</div>

<div class="page__footer-copyright">&copy; 2019 Aditya Jaishankar. Powered by <a href="https://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.</div>

      </footer>
    </div>

    
  <script src="/assets/js/main.min.js"></script>
  <script defer src="https://use.fontawesome.com/releases/v5.6.0/js/all.js" integrity="sha384-z9ZOvGHHo21RqN5De4rfJMoAxYpaVoiYhuJXPyVmSs8yn20IE3PmBM534CffwSJI" crossorigin="anonymous"></script>




<script src="/assets/js/lunr/lunr.min.js"></script>
<script src="/assets/js/lunr/lunr-store.js"></script>
<script src="/assets/js/lunr/lunr-en.js"></script>








<script type="text/javascript"
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_CHTML"></script>

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
tex2jax: {
inlineMath: [['$','$'], ['\\(','\\)']],
processEscapes: true},
jax: ["input/TeX","input/MathML","input/AsciiMath","output/CommonHTML"],
extensions: ["tex2jax.js","mml2jax.js","asciimath2jax.js","MathMenu.js","MathZoom.js","AssistiveMML.js", "[Contrib]/a11y/accessibility-menu.js"],
TeX: {
extensions: ["AMSmath.js","AMSsymbols.js","noErrors.js","noUndefined.js"],
equationNumbers: {
autoNumber: "AMS"
}
}
});
</script>


  </body>
</html>
