{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definitions and Framing\n",
    "\n",
    "* **Supervised Machine Learning:** \n",
    "    Using known data to generate some useful predictions of on unseen data\n",
    "\n",
    "    Label $y$: The target variable that we are trying to predict, for example 'spam' or 'not spam'. \n",
    "\n",
    "    Features: Something about the data that is used to represent the data, that is later fed into a model. Complicated machine learning models can have multiple features $x_1, x_2, \\ldots, x_n$. So this is a vector $\\mathbf{x}$.\n",
    "\n",
    "    Model: Maps unseen data to predictions of label $y$. It is defined by internal parameters that are learned using a training set of labeled data\n",
    "\n",
    "    Labeled data can be represented as $(\\mathbf{x}, y)$. In unlabeled data, $y$ is not known and is predicted by the model. \n",
    "\n",
    "\n",
    "* **Models**\n",
    "\n",
    "    A model defines the relationship between the features and the label. There are two key phases in the life of a model: <br>\n",
    "\n",
    "    Training: The phase where you the model is trained or learned. You show the model a number of examples of labeled data, and allow the model to learn the relationship between the features and the label. In other words, it is learning the values of the parameters in the model. These parameters in the model are often called hyperparameters. \n",
    "\n",
    "    Inference: The phase where the model is used to generate labels $y'$ given features $\\mathbf{x}$. \n",
    "    \n",
    "    \n",
    "* **Regression vs. Classification**\n",
    "\n",
    "    A regression predicts continuous values while a classification predicts discrete values. \n",
    "\n",
    "## Descending into ML\n",
    "\n",
    "Topics covered: Linear Regression, Training and Loss\n",
    "\n",
    "* The $L_2$ loss is defined as \n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "L_2 \\textrm{ Loss } = \\sum\\limits_i (y_i - prediction_i(\\mathbf{x}))^2 \n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "where we sum over all data points in the training set $i$. \n",
    "\n",
    "* The convention in machine learning is to represent the linear model as $y' = w_1 x_1 + b$ instead of the more traditional $y = mx + b$. We could easily generalize this regression from one feature to multiple features and the prediction would be given by $y' = w_1 x_1 + w_2 x_2 + w_3 x_3 + b$, where all the $w_i$'s are weights and all the $x_i$'s are features. The process of fitting the model is called training and the process of using the trained model to make a prediction is called inference. \n",
    "\n",
    "* A commonly used loss function is the mean squared error (MSE), but this is neither the only loss function nor the best or most practical loss function for all cases.\n",
    "\n",
    "## Reducing Loss\n",
    "\n",
    "* One of the popular ways to find the minimum in the loss function is to use Gradient Descent. We calculate a gradient at each point and move in the direction of decreasing gradient. The step size that we use as we advance in the direction of decreasing gradient is called the learning rate. This has to be chosen carefully: in multi-dimensional problems, too large a learning rate can cause the code to become unstable. \n",
    "\n",
    "* We can also get trapped in local minima if the space is *not-convex*. There is a whole sprawling field of non-convex optimization. \n",
    "\n",
    "* There are two important flavors of gradient descent:\n",
    "\n",
    "    **Stochastic Gradient Descent:**\n",
    "\n",
    "    In theory, while using gradient descent, we need to calculate the gradient of the loss function considering all examples. However in practice, this is found to be excessive and computationally expensive. We therefore select only one example at random and calculate the gradient of the loss function considering only that one example. This is called stochastic gradient descent. Although this might require more steps to reach the optimum, overall there is usually less computation when dealing with very large data sets. Gradient calculations can be very expensive. \n",
    "\n",
    "    Mathematically, we want to calculate \n",
    "\n",
    "    $$\n",
    "    \\begin{align}\n",
    "    w_{n+1} = w_n -\\eta Q(w)\n",
    "    \\end{align}\n",
    "    $$\n",
    "\n",
    "    where $\\eta$ is the learning rate and $Q(w) = \\frac{1}{N}\\sum_i Q_i(w)$ is the $L_2$ loss for the $i$-th example. What we do instead, in stochastic gradient descent is to first randomnly pick a particular example $k$ and calculate the loss function $Q_k(w)$ and then update $w$ using:\n",
    "\n",
    "    $$\n",
    "    \\begin{align}\n",
    "    w_{n+1} = w_n -\\eta Q_k(w)\n",
    "    \\end{align}\n",
    "    $$\n",
    "\n",
    "    and perform this iteratively until the minimum criterion is reached. \n",
    "\n",
    "    When there are multiple parameters to optimize, the gradient is of course a vector, and so is $\\mathbf{w} = (w_1, w_2, \\ldots)$ and we proceed in the direction of steepest gradient in steps $\\eta$ large. \n",
    "\n",
    "    **Mini-batch Gradient Descent**\n",
    "\n",
    "    This is very similar to stochastic gradient descent except that instead of taking only one data point, we take batches of 10 or 100 of them.  Especially with datasets that contain duplicates, enormous datasets do not contain any further information than very large datasets. Mini-batch gradient descent exploits this fact and works very well in practice. Typical values of batch-size range between 10 and 1000. Stochastic gradient descent is an extreme example of mini-batch gradient descent with batch size 1.\n",
    "\n",
    "* The algorithm to train the model in this case is iterative: we start with some intial guesses for the parameters, compute the loss function for those values, update the values of the parameters through some scheme (with the goal of moving in the direction of lower loss), calculate the loss for the updated values of the parameters, and proceed iteratively until we achieve convergence. Convergence is usually assumed when the loss becomes below some threshold value, or if the loss function starts changing extremely slowly. \n",
    "\n",
    "## First steps with TensorFlow\n",
    "\n",
    "* TensnsorFlow is a computational framework that allows you to build machine learning models. We can use both lower level APIs by defining models based on a series of mathematical operations or we could use predefined higher level APIs such as `tf.estimator`. These architectures can be linear regressors or neural networks. \n",
    "\n",
    "* TensorFlow consists of the following two components:\n",
    "\n",
    "    0. A graph protocol buffer\n",
    "    0. A runtime that executes the distributed graph\n",
    "\n",
    "* The **graph protocol buffer** or protobuf takes data structures written in a text file and then generates classes in Python (or other language) that allows you to load, save and interact with the data in a user friendly way. In this sense the protobuf and the runtime are akin to Python code and a Python interpreter. \n",
    "\n",
    "* Because TensorFlow is built using APIs of various levels of abstraction, we have a choice of level. In general, I should chose the layer that offers the highest level of abstraction. Of course, the highest layers are also less flexible, so for some special modeling cases if I need more flexibility, I can just drop one run lower in the level of API. \n",
    "\n",
    "### `tf.estimator` API\n",
    "\n",
    "The `tf.estimator` API is one of the highest level APIs that has a lot of prepackaged tools of use. Below we show some code to exemplify its use. In the example below, we are going to estimate the median housing pricebased on just one input feature. The data is from the 1990 California housing census data. Available [here](https://developers.google.com/machine-learning/crash-course/california-housing-data-description). First we perform some imports:\n",
    "\n",
    "### Step 0: Setup, imports, loading and inspecting the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** `tensorflow` does not work with `python 3.7.x` yet. I had `python 3.7.2` loaded on my machine, so this was a good exercise in understanding `conda environments`. It is recommended that each project have ita own *environment*, which consists of a python ditribution (which can be versioned) and a series of packages (which can also be versioned). we first use \n",
    "\n",
    "`conda env --name <envname>`\n",
    "\n",
    "`-n` can be used instead of `--name`. The environment can be created with all the required packages in one line as follows (recommended):\n",
    "\n",
    "`conda env -n tensorflowenv python=3.6 scipy numpy matplotlib scikit-learn`\n",
    "\n",
    "Here `tensorflowenv` is the environment name that I choose to give. I then go into the new environment using\n",
    "\n",
    "`conda activate tensorflowenv`\n",
    "\n",
    "Now `jupyter` doesn't yet recognize this new kernel, so I need to manually go and install it (for each environment I create) using the following (see [here](https://stackoverflow.com/questions/39604271/conda-environments-not-showing-up-in-jupyter-notebook?rq=1) for more details:)\n",
    "\n",
    "`python -m ipykernel install --name tensorflowenv --display-name \"Python (tendorflowenv)\"`\n",
    "\n",
    "Now when I invoke `jupyter notebook` in the activate environment, I can use the dropdown menu to activate the kernel with the specific python version and packages that I desire. Also note that invoking `conda install pkgname` in the activated environment only installs the `pkgname` for that particular environment. \n",
    "\n",
    "For more information regarding environments, see the [docs](https://conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from matplotlib import cm\n",
    "from matplotlib import gridspec\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.python.data import Dataset\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "pd.options.display.max_rows = 10\n",
    "pd.options.display.float_format = '{:.1f}'.format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We next load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "california_housing_dataframe = pd.read_csv('https://download.mlcc.google.com/mledu-datasets/california_housing_train.csv', sep=',')\n",
    "\n",
    "california_housing_dataframe = california_housing_dataframe.reindex(\n",
    "    np.random.permutation(california_housing_dataframe.index))\n",
    "california_housing_dataframe['median_house_value'] /= 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8229</th>\n",
       "      <td>-118.4</td>\n",
       "      <td>34.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>4780.0</td>\n",
       "      <td>1192.0</td>\n",
       "      <td>1886.0</td>\n",
       "      <td>1036.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13167</th>\n",
       "      <td>-121.9</td>\n",
       "      <td>37.3</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1844.0</td>\n",
       "      <td>340.0</td>\n",
       "      <td>719.0</td>\n",
       "      <td>305.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>235.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12736</th>\n",
       "      <td>-121.8</td>\n",
       "      <td>37.3</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1959.0</td>\n",
       "      <td>292.0</td>\n",
       "      <td>891.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>7.4</td>\n",
       "      <td>338.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>838</th>\n",
       "      <td>-117.1</td>\n",
       "      <td>32.7</td>\n",
       "      <td>26.0</td>\n",
       "      <td>4151.0</td>\n",
       "      <td>823.0</td>\n",
       "      <td>2822.0</td>\n",
       "      <td>697.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>123.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8966</th>\n",
       "      <td>-118.9</td>\n",
       "      <td>35.2</td>\n",
       "      <td>29.0</td>\n",
       "      <td>2888.0</td>\n",
       "      <td>753.0</td>\n",
       "      <td>2949.0</td>\n",
       "      <td>699.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>45.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "8229      -118.4      34.0                18.0       4780.0          1192.0   \n",
       "13167     -121.9      37.3                40.0       1844.0           340.0   \n",
       "12736     -121.8      37.3                21.0       1959.0           292.0   \n",
       "838       -117.1      32.7                26.0       4151.0           823.0   \n",
       "8966      -118.9      35.2                29.0       2888.0           753.0   \n",
       "\n",
       "       population  households  median_income  median_house_value  \n",
       "8229       1886.0      1036.0            4.5               500.0  \n",
       "13167       719.0       305.0            3.4               235.2  \n",
       "12736       891.0       300.0            7.4               338.4  \n",
       "838        2822.0       697.0            2.8               123.4  \n",
       "8966       2949.0       699.0            1.8                45.5  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "california_housing_dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now going to use `total_rooms` as an input feature to predict our target (or label) `median_house_value`.  Note that the data is at the city block level, so the feature represents the total number of rooms in the block. We are going to use the `tf.estimator` API to implement a linear regressor to model the data. The API already implements a lot of the low-level nuts and bolts of the regression (or in general, other models) so we can focus on the training, evaluating, and visualizing aspects of the process. The specific class we will use is the `tf.estimator.LinearRegressor` class. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Defining the features \n",
    "\n",
    "There are two main classes of features: \n",
    "\n",
    "* **categorical:** a feature that can take on discrete values, like spam/not spam, sunny/rainy/cloudy, etc.\n",
    "\n",
    "* **neumerical:** a feature that can take on continuous or a large number of discrete values, like price, temperature, etc. It seems that these are features that we can do arithmetic on. \n",
    "\n",
    "In TensorFlow, we need to define what kind of feature we are working with. In our case, because we are working with `total_rooms` in this example, it is a numerical feature. This identification of the type of feature is done using `tf.feature_column` module, which has various functions built into it. See [here](https://www.tensorflow.org/guide/feature_columns) for documentation. Feature columns only contain a description of the data and not the data itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_feature = california_housing_dataframe[['total_rooms']]\n",
    "feature_columns = [tf.feature_column.numeric_column('total_rooms')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Defining the target\n",
    "\n",
    "We want to predict the meadian house value given the number of rooms, so this is our target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = california_housing_dataframe['median_house_value']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Configure the LinearRegressor\n",
    "\n",
    "We now configure a linear regression model using `LinearRegressor`. The optimization itself is carried out using a built-in implementation of mini-batch stochastic gradient descent. We also use the `tf.contrib.estimator.clip_gradients_by_norm` functions to impose a cut off on the step size so that the gradient descent doesn't become unstable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.0000001)\n",
    "my_optimizer = tf.contrib.estimator.clip_gradients_by_norm(my_optimizer, 5.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_regressor = tf.estimator.LinearRegressor(feature_columns=feature_columns,\n",
    "                                                optimizer=my_optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Define the input function\n",
    "\n",
    "We now need to define an input function which tells tensorflow how to preprocess the data as well as how to batch, shuffle, and repeat it during model training. This function is a bit of a jump from what we have seen so far, so we will explore it step by step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_input_fn(features, targets, batch_size=1, shuffle=True, num_epochs=None):\n",
    "    \"\"\"Trains a linear regression model with one feature\n",
    "    Inputs: \n",
    "        features: a pandas dataframe of features\n",
    "        targets: a pandas dataframe of targets\n",
    "        batch_size: size of batches to be passed to the model\n",
    "        shuffle: Boolean, whether to shuffle the training data or not\n",
    "        num_epochs: number of epochs for which the data should be repeated. None means repeat indefinitely\n",
    "    Returns:\n",
    "        Tuple of (features, label) for the next data batch\n",
    "    \"\"\"\n",
    "    # convert pandas data into a dict of numpy arrays\n",
    "    features = {key:np.array(value) for (key, value) in dict(features).items()} # line 13\n",
    "    \n",
    "    # Construct a dataset and configure batching and repeating\n",
    "    ds = Dataset.from_tensor_slices((features,targets)) # line 16\n",
    "    ds = ds.batch(batch_size).repeat(num_epochs) # line 17\n",
    "    \n",
    "    # Shuffle the data if needed\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size=10000) # line 21\n",
    "        \n",
    "    # return the next batch of data\n",
    "    features, labels = ds.make_one_shot_iterator().get_next() # line 24\n",
    "    return (features, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an explanation by line number of the code above. \n",
    "\n",
    "* **line 13:**\n",
    "    `features` is a pandas dictionary, and `dict(features)` converts it into a dictionary with the column name as key and all the values in the column as pandas series of values. Therefore, the items generates an iterator of type `(feature_name, values)`, which we use to generate our feature dictionary. `values` is of type `pandas.Series.`\n",
    "\n",
    "* **lines 16:**\n",
    "\n",
    "    This line makes use of the `tf.data` API, which lets you take in distributed data from various sources and transform it in different ways to generate datasets for machine learning models. There are two cheif abstractions that `tf.data` introduces, one of which is the `tf.data.Dataset` module (the other is the `tf.data.Iterator` module which is used in line 24 and discussed next). Using `tf.data.Dataset`, there are two distinct ways to create a dataset:    \n",
    "\n",
    "    1. Creating a source (for example `Dataset.from_tensor_slices()`) which constructs a dataset from one or more `tf.Tensor` objects. \n",
    "    2. Applying a transformations (for example `Dataset.batch()`) which constructs a dataset from one or more `tf.data.Datasets` objects. \n",
    "    \n",
    "    A tensor object is in principle a matrix of n-dimensions, except that its value is not evaluated until called for using a `tf.run()` command. The objects can be passed into operations to yield other tensor objects, but again, actual evaluation of the numerical value of the tensor is held off until later. This enables the *flow* of a tensor through various operations without numerical evaluation. With this context, what line 16 is doing is the following: \n",
    "    \n",
    "    `Dataset.from_tensor_slices()` returns a dataset for each row of the input tensor. For example the code snippet below would return `[1, 2], [3, 4]` for the variable `ds`. In our case, we provide a tuple of the form `(features, targets)`, where `features` is a dictionary, and `targets` is a number, `from_tensor_slices` would essentially unpack this tuple, to provide multiple datasets, each of the form `(key: values, target)`.\n",
    "    \n",
    "```python\n",
    "    t = tf.constant([[1, 2], [3, 4]])\n",
    "    ds = tf.data.Dataset.from_tensor_slices(t)   # [1, 2], [3, 4]\n",
    "```\n",
    "\n",
    "* **line 17:**\n",
    "    `Dataset.batch(batch_size)` transform the dataset object that constructs a dataset using `batch_size` number of consecutive elements. The `.repeat(count)` call at the end repeats this dataset `count` number of times.\n",
    "\n",
    "* **line 21:**\n",
    "    `Dataset.shuffle(buffer_size)` randomnly shuffles the elements of this dataset. The `buffer_size` argument represents the number of elements from this dataset from which the new dataset will sample. (Why not sample from the whole dataset to make it even more random? Perhaps computational constraints for very large datasets. \n",
    "    \n",
    "* **line 24:** \n",
    "    `Dataset.make_one_shot_iterator()` generates an iterator for iterating over the dataset (think generators in python). The `.get_next()` call at the end yields the next elements in the dataset. \n",
    "    \n",
    "This input function is going to be used again in later exercises so make sure you understand it well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Train the model\n",
    "\n",
    "We now call `train()` on `linear_regressor` to train the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = linear_regressor.train(\n",
    "    input_fn=lambda: my_input_fn(my_feature, targets),\n",
    "    steps=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The use of the `lambda` function is somewhat unclear to me. It seems that it ensures that the input function is truly randomized, instead of manually passing in randomized datasets?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model\n",
    "\n",
    "We now just make predictions on the training data to see how well the model fit it during training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (on training data): 56251.030\n",
      "Root Mean Squared Error (on training data): 237.173\n"
     ]
    }
   ],
   "source": [
    "# Create an input function for predictions\n",
    "prediction_input_fn = lambda: my_input_fn(my_feature, targets, num_epochs=1, shuffle=False)\n",
    "\n",
    "# Call predict on the linear_regressor to make predictions\n",
    "predictions = linear_regressor.predict(input_fn=prediction_input_fn)\n",
    "\n",
    "#Format predictions as a numpy array so we can calculate error metrics\n",
    "predictions = np.array([item['predictions'][0] for item in predictions])\n",
    "\n",
    "#Calculate the mean squared error and the root mean squared error\n",
    "mean_squared_error = metrics.mean_squared_error(predictions, targets)\n",
    "root_mean_squared_error = math.sqrt(mean_squared_error)\n",
    "print(\"Mean Squared Error (on training data): %0.3f\" % mean_squared_error)\n",
    "print(\"Root Mean Squared Error (on training data): %0.3f\" % root_mean_squared_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To know if this mse and rmse is any good, we compare the rmse to the difference between the min and max of our targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min. Median House Value: 14.999\n",
      "Max. Median House Value: 500.001\n",
      "Difference between Min. and Max.: 485.002\n",
      "Root Mean Squared Error: 237.173\n"
     ]
    }
   ],
   "source": [
    "min_house_value = california_housing_dataframe[\"median_house_value\"].min()\n",
    "max_house_value = california_housing_dataframe[\"median_house_value\"].max()\n",
    "min_max_difference = max_house_value - min_house_value\n",
    "\n",
    "print(\"Min. Median House Value: %0.3f\" % min_house_value)\n",
    "print(\"Max. Median House Value: %0.3f\" % max_house_value)\n",
    "print(\"Difference between Min. and Max.: %0.3f\" % min_max_difference)\n",
    "print(\"Root Mean Squared Error: %0.3f\" % root_mean_squared_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This seems really large - the rmse is nearly 50% of the max difference. Let us first look at some summary statistics on how well the model is doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictions</th>\n",
       "      <th>targets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>17000.0</td>\n",
       "      <td>17000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.4</td>\n",
       "      <td>207.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.3</td>\n",
       "      <td>116.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.2</td>\n",
       "      <td>119.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.3</td>\n",
       "      <td>180.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.5</td>\n",
       "      <td>265.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.7</td>\n",
       "      <td>500.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       predictions  targets\n",
       "count      17000.0  17000.0\n",
       "mean           0.4    207.3\n",
       "std            0.3    116.0\n",
       "min            0.0     15.0\n",
       "25%            0.2    119.4\n",
       "50%            0.3    180.4\n",
       "75%            0.5    265.0\n",
       "max            5.7    500.0"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calibration_data = pd.DataFrame()\n",
    "calibration_data['predictions'] = pd.Series(predictions)\n",
    "calibration_data['targets'] = pd.Series(targets)\n",
    "calibration_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting the data\n",
    "\n",
    "sample = california_housing_dataframe.sample(n=300)\n",
    "\n",
    "# Get the min and max total_rooms values.\n",
    "x_0 = sample[\"total_rooms\"].min()\n",
    "x_1 = sample[\"total_rooms\"].max()\n",
    "\n",
    "# Retrieve the final weight and bias generated during training.\n",
    "weight = linear_regressor.get_variable_value('linear/linear_model/total_rooms/weights')[0]\n",
    "bias = linear_regressor.get_variable_value('linear/linear_model/bias_weights')\n",
    "\n",
    "# Get the predicted median_house_values for the min and max total_rooms values.\n",
    "y_0 = weight * x_0 + bias \n",
    "y_1 = weight * x_1 + bias\n",
    "\n",
    "# Plot our regression line from (x_0, y_0) to (x_1, y_1).\n",
    "plt.plot([x_0, x_1], [y_0, y_1], c='r') # Plotting the line using just 2 points\n",
    "\n",
    "# Label the graph axes.\n",
    "plt.ylabel(\"median_house_value\")\n",
    "plt.xlabel(\"total_rooms\")\n",
    "\n",
    "# Plot a scatter plot from our data sample.\n",
    "plt.scatter(sample[\"total_rooms\"], sample[\"median_house_value\"])\n",
    "\n",
    "# Display graph.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rest of the exercise goes into a discussion on tweaking the hyperparameters to overcome this por fit. With a suitable choice of `learning_rate`, `steps` and `batch_size` we can get a reasonably good fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflowenv]",
   "language": "python",
   "name": "conda-env-tensorflowenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
